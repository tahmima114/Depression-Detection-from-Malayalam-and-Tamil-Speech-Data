{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14990500,"datasetId":9595634,"databundleVersionId":15864649}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, random\nimport numpy as np\nimport torch\n\nSEED = 42\n\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# Optional: stronger determinism (may error if some ops are nondeterministic)\n# torch.use_deterministic_algorithms(True)\n\ndef seed_worker(worker_id):\n    worker_seed = SEED + worker_id\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:21:12.125143Z","iopub.execute_input":"2026-02-28T07:21:12.125822Z","iopub.status.idle":"2026-02-28T07:21:15.726080Z","shell.execute_reply.started":"2026-02-28T07:21:12.125793Z","shell.execute_reply":"2026-02-28T07:21:15.725499Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Resample\nRead Tamil from Kaggle input and save 16k audio to working directory","metadata":{}},{"cell_type":"code","source":"# =============================\n# ‚úÖ BLOCK 2: Resample Tamil dataset to 16k safely\n# - Reads from /content/Tamil\n# - Writes to /content/Tamil_16k\n# =============================\nimport os, glob\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom tqdm import tqdm\n\nSRC_ROOT = \"/kaggle/input/datasets/tahmimahoque/depression-det/Depression_det/Depression_det/Tamil/Tamil\"\nDST_ROOT = \"/kaggle/working/Tamil_16k\"\nTARGET_SR = 16000\n\npairs = [\n    (os.path.join(SRC_ROOT, \"Depressed\", \"Train_set\"),\n     os.path.join(DST_ROOT, \"Depressed\", \"Train_set\")),\n    (os.path.join(SRC_ROOT, \"Non-depressed\", \"Train_set\"),\n     os.path.join(DST_ROOT, \"Non-depressed\", \"Train_set\")),\n]\n\nos.makedirs(DST_ROOT, exist_ok=True)\n\ntotal = converted = same_sr = failed = 0\n\nfor src_dir, dst_dir in pairs:\n    os.makedirs(dst_dir, exist_ok=True)\n\n    files = glob.glob(os.path.join(src_dir, \"**/*.wav\"), recursive=True) + \\\n            glob.glob(os.path.join(src_dir, \"**/*.WAV\"), recursive=True)\n\n    total += len(files)\n\n    for fp in tqdm(files, desc=f\"Resampling {os.path.basename(os.path.dirname(src_dir))}/{os.path.basename(src_dir)}\"):\n        try:\n            y, sr = librosa.load(fp, sr=None, mono=True)\n\n            # ‚úÖ Trim silence (helps both MFCC + W2V2)\n            y, _ = librosa.effects.trim(y, top_db=30)\n\n            # ‚úÖ Resample if needed\n            if sr != TARGET_SR:\n                y = librosa.resample(y, orig_sr=sr, target_sr=TARGET_SR)\n                converted += 1\n            else:\n                same_sr += 1\n\n            # ‚úÖ Safe RMS normalize (no noise blow-up like peak normalize)\n            rms = float(np.sqrt(np.mean(y**2) + 1e-8))\n            y = y / max(rms, 1e-3)\n            y = np.clip(y, -1.0, 1.0)\n\n            out_path = os.path.join(dst_dir, os.path.basename(fp))\n            sf.write(out_path, y, TARGET_SR, subtype=\"PCM_16\")\n\n        except Exception as e:\n            failed += 1\n\nprint(\"\\n==== DONE ====\")\nprint(\"Total files:\", total)\nprint(\"Already 16k:\", same_sr)\nprint(\"Resampled:\", converted)\nprint(\"Failed:\", failed)\n\n# ‚úÖ Quick verify SR\nimport random\ncheck = glob.glob(os.path.join(DST_ROOT, \"**/*.wav\"), recursive=True)\nsample = random.sample(check, min(20, len(check)))\n\nsrs = []\nfor fp in sample:\n    _, sr = librosa.load(fp, sr=None, mono=True)\n    srs.append(sr)\n\nvals, cnts = np.unique(srs, return_counts=True)\nprint(\"New folder SR counts:\", dict(zip(vals.tolist(), cnts.tolist())))\nprint(\"‚úÖ New root:\", DST_ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:23:39.358558Z","iopub.execute_input":"2026-02-28T07:23:39.359009Z","iopub.status.idle":"2026-02-28T07:24:16.340194Z","shell.execute_reply.started":"2026-02-28T07:23:39.358976Z","shell.execute_reply":"2026-02-28T07:24:16.339438Z"}},"outputs":[{"name":"stderr","text":"Resampling Depressed/Train_set: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 454/454 [00:20<00:00, 22.46it/s]\nResampling Non-depressed/Train_set: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 920/920 [00:15<00:00, 57.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n==== DONE ====\nTotal files: 1374\nAlready 16k: 454\nResampled: 920\nFailed: 0\nNew folder SR counts: {16000: 20}\n‚úÖ New root: /kaggle/working/Tamil_16k\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Build Metadata\n\nCreate CSV from resampled Tamil_16k with labels and speaker IDs","metadata":{}},{"cell_type":"code","source":"# =============================\n# ‚úÖ BLOCK 1: Build metadata CSV (from Tamil_16k)\n# =============================\nimport os, glob, re\nimport pandas as pd\n\nDATA_ROOT_16K = \"/kaggle/working/Tamil_16k\"\n\ndep_train = os.path.join(DATA_ROOT_16K, \"Depressed\", \"Train_set\")\nnd_train  = os.path.join(DATA_ROOT_16K, \"Non-depressed\", \"Train_set\")\n\nimport re, os\n\ndef extract_speaker_from_path(fp: str) -> str:\n    base = os.path.splitext(os.path.basename(fp))[0]\n\n    # Non-depressed: ND1, ND2...\n    m = re.match(r\"^(ND\\d+)\", base, flags=re.IGNORECASE)\n    if m:\n        return m.group(1).upper()\n\n    # Depressed: D_<SPK>_... OR D_<SPK>-<rep>\n    if base.startswith(\"D_\"):\n        rest = base[2:]                 # remove D_\n        tok  = rest.split(\"_\")[0]       # first token after D_\n        tok  = re.sub(r\"[-_][0-9a-zA-Z]+$\", \"\", tok)  # remove trailing -3, _c, -2 etc.\n        return tok.upper()\n\n    # fallback\n    tok = base.split(\"_\")[0]\n    tok = re.sub(r\"[-_][0-9a-zA-Z]+$\", \"\", tok)\n    return tok.upper()\n\nrows = []\n\ndef collect(folder, label):\n    wavs = glob.glob(os.path.join(folder, \"*.wav\")) + glob.glob(os.path.join(folder, \"*.WAV\"))\n    print(f\"{folder} -> {len(wavs)} files\")\n    for f in wavs:\n        fname = os.path.splitext(os.path.basename(f))[0]\n        spk   = extract_speaker_from_path(f)\n        rows.append({\n            \"file_path\": f,\n            \"label\": int(label),\n            \"fname\": fname,\n            \"speaker\": spk\n        })\n\ncollect(dep_train, 1)\ncollect(nd_train, 0)\n\ndf = pd.DataFrame(rows)\n\nprint(\"\\n‚úÖ Total samples:\", len(df))\nprint(\"‚úÖ Label counts:\\n\", df[\"label\"].value_counts())\nprint(\"‚úÖ Unique speakers:\", df[\"speaker\"].nunique())\nprint(\"‚úÖ Speakers per label:\\n\", df.groupby(\"label\")[\"speaker\"].nunique())\n\nOUT_CSV = f\"{DATA_ROOT_16K}/tamil_trainval_16k.csv\"\ndf.to_csv(OUT_CSV, index=False)\nprint(\"\\n‚úÖ Saved:\", OUT_CSV)\n\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:25:31.058382Z","iopub.execute_input":"2026-02-28T07:25:31.059160Z","iopub.status.idle":"2026-02-28T07:25:31.120867Z","shell.execute_reply.started":"2026-02-28T07:25:31.059128Z","shell.execute_reply":"2026-02-28T07:25:31.120284Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/Tamil_16k/Depressed/Train_set -> 454 files\n/kaggle/working/Tamil_16k/Non-depressed/Train_set -> 920 files\n\n‚úÖ Total samples: 1374\n‚úÖ Label counts:\n label\n0    920\n1    454\nName: count, dtype: int64\n‚úÖ Unique speakers: 44\n‚úÖ Speakers per label:\n label\n0     5\n1    39\nName: speaker, dtype: int64\n\n‚úÖ Saved: /kaggle/working/Tamil_16k/tamil_trainval_16k.csv\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                           file_path  label       fname  \\\n0  /kaggle/working/Tamil_16k/Depressed/Train_set/...      1   D_F2001_b   \n1  /kaggle/working/Tamil_16k/Depressed/Train_set/...      1  D_F10021-1   \n2  /kaggle/working/Tamil_16k/Depressed/Train_set/...      1  D_F10013-4   \n3  /kaggle/working/Tamil_16k/Depressed/Train_set/...      1  D_S00_28-2   \n4  /kaggle/working/Tamil_16k/Depressed/Train_set/...      1  D_S00_26-3   \n\n  speaker  \n0   F2001  \n1  F10021  \n2  F10013  \n3     S00  \n4     S00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_path</th>\n      <th>label</th>\n      <th>fname</th>\n      <th>speaker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/Tamil_16k/Depressed/Train_set/...</td>\n      <td>1</td>\n      <td>D_F2001_b</td>\n      <td>F2001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/Tamil_16k/Depressed/Train_set/...</td>\n      <td>1</td>\n      <td>D_F10021-1</td>\n      <td>F10021</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/Tamil_16k/Depressed/Train_set/...</td>\n      <td>1</td>\n      <td>D_F10013-4</td>\n      <td>F10013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/Tamil_16k/Depressed/Train_set/...</td>\n      <td>1</td>\n      <td>D_S00_28-2</td>\n      <td>S00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/Tamil_16k/Depressed/Train_set/...</td>\n      <td>1</td>\n      <td>D_S00_26-3</td>\n      <td>S00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Speaker sanity check","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\n\ndf = pd.read_csv(\"/kaggle/working/Tamil_16k/tamil_trainval_16k.csv\")\n\nprint(\"Total rows:\", len(df))\nprint(\"Unique speakers:\", df[\"speaker\"].nunique())\nprint(\"Speakers per label:\\n\", df.groupby(\"label\")[\"speaker\"].nunique())\n\n# 1) Mixed-label speakers check (speaker leakage risk)\nmix = df.groupby(\"speaker\")[\"label\"].nunique()\nmixed = mix[mix > 1]\nprint(\"\\nMixed-label speakers (should be 0):\", len(mixed))\nif len(mixed):\n    print(mixed.head(20))\n\n# 2) Show top speakers by #files (helps spot parsing bug)\nprint(\"\\nTop 15 speakers by file-count:\")\nprint(df[\"speaker\"].value_counts().head(15))\n\n# 3) Pattern check: speakers that look suspicious (not ND#, not S##, not F#### etc.)\ndef is_ok_spk(s):\n    s = str(s)\n    if re.fullmatch(r\"ND\\d+\", s): return True\n    if re.fullmatch(r\"S\\d+\", s): return True          # S00, S01...\n    if re.fullmatch(r\"F\\d+\", s): return True          # F2006...\n    if re.fullmatch(r\"[A-Z]\\d+\", s): return True      # A1 type (just in case)\n    return False\n\nbad = df[~df[\"speaker\"].apply(is_ok_spk)]\nprint(\"\\nSuspicious speaker IDs:\", bad[\"speaker\"].nunique())\nprint(bad[[\"fname\",\"speaker\",\"label\"]].head(30))\n\n# 4) Depressed files where speaker still contains '-' or '_' at end (bad trimming)\nbad_dep = df[(df[\"label\"]==1) & (df[\"speaker\"].str.contains(r\"[-_]\", regex=True))]\nprint(\"\\nDepressed speakers containing '-' or '_' (should be 0 ideally):\", bad_dep[\"speaker\"].nunique())\nprint(bad_dep[[\"fname\",\"speaker\"]].head(30))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:26:46.103713Z","iopub.execute_input":"2026-02-28T07:26:46.104331Z","iopub.status.idle":"2026-02-28T07:26:46.126424Z","shell.execute_reply.started":"2026-02-28T07:26:46.104304Z","shell.execute_reply":"2026-02-28T07:26:46.125746Z"}},"outputs":[{"name":"stdout","text":"Total rows: 1374\nUnique speakers: 44\nSpeakers per label:\n label\n0     5\n1    39\nName: speaker, dtype: int64\n\nMixed-label speakers (should be 0): 0\n\nTop 15 speakers by file-count:\nspeaker\nS00       241\nND3       184\nND1       184\nND2       184\nND4       184\nND5       184\nA00        80\nF10011      4\nF10013      4\nF20014      4\nF10021      4\nF2001       4\nF1008       4\nF2004       4\nF20011      4\nName: count, dtype: int64\n\nSuspicious speaker IDs: 0\nEmpty DataFrame\nColumns: [fname, speaker, label]\nIndex: []\n\nDepressed speakers containing '-' or '_' (should be 0 ideally): 0\nEmpty DataFrame\nColumns: [fname, speaker]\nIndex: []\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Speaker Split\n\nSpeaker-stratified train/val split","metadata":{}},{"cell_type":"code","source":"# =============================\n# ‚úÖ BLOCK 3 (BEST): Speaker-stratified Train/Val split (safe + balanced)\n# - VAL gets: 1 ND speaker + ~20% Dep speakers (min 2)\n# - Deterministic (seed=42)\n# Output: /content/Tamil_16k/tamil_trainval_16k_stratspk.csv\n# =============================\nimport numpy as np\nimport pandas as pd\n\nIN_CSV  = \"/kaggle/working/Tamil_16k/tamil_trainval_16k.csv\"\nOUT_CSV = \"/kaggle/working/Tamil_16k/tamil_trainval_16k_stratspk.csv\"\n\ndf = pd.read_csv(IN_CSV)\n\n# 0) Hard sanity: no mixed-label speakers\nmix = df.groupby(\"speaker\")[\"label\"].nunique()\nmixed = mix[mix > 1]\nassert len(mixed) == 0, f\"‚ùå Mixed-label speakers found: {len(mixed)}. Fix speaker parsing first.\"\n\n# 1) Speaker -> label\nspk_label = df.groupby(\"speaker\")[\"label\"].agg(lambda x: int(x.value_counts().idxmax())).reset_index()\ndep_spk = spk_label[spk_label[\"label\"] == 1][\"speaker\"].tolist()\nnd_spk  = spk_label[spk_label[\"label\"] == 0][\"speaker\"].tolist()\n\nprint(\"‚úÖ Dep speakers:\", len(dep_spk), \"| ND speakers:\", len(nd_spk))\n\n# 2) Choose VAL speakers\nrng = np.random.default_rng(42)\n\n# ND speakers are only 5 -> keep VAL ND = 1 (best compromise)\nn_nd_val = 1 if len(nd_spk) >= 2 else len(nd_spk)\n\n# Dep speakers are many -> take 20% but at least 2\nval_frac_dep = 0.20\nn_dep_val = int(round(len(dep_spk) * val_frac_dep))\nn_dep_val = max(2, n_dep_val) if len(dep_spk) >= 2 else len(dep_spk)\n\nval_nd  = set(rng.choice(nd_spk,  size=n_nd_val, replace=False).tolist()) if n_nd_val > 0 else set()\nval_dep = set(rng.choice(dep_spk, size=n_dep_val, replace=False).tolist()) if n_dep_val > 0 else set()\n\nval_spk = val_nd | val_dep\n\n# 3) Assign split\ndf[\"split\"] = \"train\"\ndf.loc[df[\"speaker\"].isin(val_spk), \"split\"] = \"val\"\n\n# 4) Checks\nprint(\"\\n‚úÖ Split counts:\\n\", df[\"split\"].value_counts())\nprint(\"\\n‚úÖ Label counts by split:\\n\", df.groupby([\"split\",\"label\"]).size())\nprint(\"\\n‚úÖ Speakers by split:\\n\", df.groupby(\"split\")[\"speaker\"].nunique())\n\ntrain_spk = set(df[df[\"split\"]==\"train\"][\"speaker\"])\nval_spk2  = set(df[df[\"split\"]==\"val\"][\"speaker\"])\noverlap = train_spk & val_spk2\nprint(\"\\n‚úÖ Speaker overlap (MUST be empty):\", overlap)\n\nassert len(overlap) == 0, \"‚ùå Speaker leakage: overlap is NOT empty!\"\n\n# 5) Save\ndf.to_csv(OUT_CSV, index=False)\nprint(\"\\n‚úÖ Saved:\", OUT_CSV)\n\nprint(\"\\nVAL speakers (for record):\", sorted(list(val_spk2)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:28:14.735134Z","iopub.execute_input":"2026-02-28T07:28:14.735696Z","iopub.status.idle":"2026-02-28T07:28:14.778896Z","shell.execute_reply.started":"2026-02-28T07:28:14.735666Z","shell.execute_reply":"2026-02-28T07:28:14.778071Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dep speakers: 39 | ND speakers: 5\n\n‚úÖ Split counts:\n split\ntrain    1158\nval       216\nName: count, dtype: int64\n\n‚úÖ Label counts by split:\n split  label\ntrain  0        736\n       1        422\nval    0        184\n       1         32\ndtype: int64\n\n‚úÖ Speakers by split:\n split\ntrain    35\nval       9\nName: speaker, dtype: int64\n\n‚úÖ Speaker overlap (MUST be empty): set()\n\n‚úÖ Saved: /kaggle/working/Tamil_16k/tamil_trainval_16k_stratspk.csv\n\nVAL speakers (for record): ['F10011', 'F10015', 'F10021', 'F10022', 'F1007', 'F2001', 'F20011', 'F20015', 'ND1']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# MFCC","metadata":{}},{"cell_type":"code","source":"import os, random\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import f1_score\n\n# =============================\n# 0) Reproducibility (IMPORTANT)\n# =============================\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nCSV_PATH = \"/kaggle/working/Tamil_16k/tamil_trainval_16k_stratspk.csv\"\nSAVE_DIR = \"/kaggle/working/models_tamil\"\nos.makedirs(SAVE_DIR, exist_ok=True)\n\ndf = pd.read_csv(CSV_PATH)\n\n# =============================\n# 1) MFCC extraction\n# =============================\ndef extract_mfcc(file_path, target_sr=16000, n_mfcc=40, max_len=320):\n    y, sr = librosa.load(file_path, sr=target_sr, mono=True)\n\n    # (optional) trim silence to reduce padding waste (safe)\n    y, _ = librosa.effects.trim(y, top_db=30)\n\n    mfcc = librosa.feature.mfcc(y=y, sr=target_sr, n_mfcc=n_mfcc)  # [n_mfcc, T]\n\n    # utterance-level CMVN (safe)\n    mfcc = (mfcc - mfcc.mean()) / (mfcc.std() + 1e-6)\n\n    T = mfcc.shape[1]\n    if T < max_len:\n        mfcc = np.pad(mfcc, ((0, 0), (0, max_len - T)), mode=\"constant\")\n    else:\n        mfcc = mfcc[:, :max_len]\n\n    return mfcc.astype(np.float32)\n\nclass TamilMFCCDataset(Dataset):\n    def __init__(self, df, split):\n        self.df = df[df[\"split\"] == split].reset_index(drop=True)\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        x = extract_mfcc(row[\"file_path\"])\n        y = int(row[\"label\"])\n        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n\ntrain_ds = TamilMFCCDataset(df, \"train\")\nval_ds   = TamilMFCCDataset(df, \"val\")\n\n# =============================\n# 2) DataLoader (balanced sampling helps a lot)\n# =============================\ndef seed_worker(worker_id):\n    s = SEED + worker_id\n    np.random.seed(s); random.seed(s)\n\ng = torch.Generator()\ng.manual_seed(SEED)\n\n# WeightedRandomSampler for TRAIN only (handles skew better than only class weights)\ntrain_labels = df[df[\"split\"]==\"train\"][\"label\"].astype(int).values\nclass_counts = np.bincount(train_labels, minlength=2)          # [count0, count1]\nclass_weights = 1.0 / np.maximum(class_counts, 1)             # inverse freq\nsample_weights = class_weights[train_labels]                  # per sample weight\n\nsampler = WeightedRandomSampler(\n    weights=torch.tensor(sample_weights, dtype=torch.double),\n    num_samples=len(sample_weights),\n    replacement=True\n)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=32,\n    sampler=sampler,              # ‚úÖ use sampler instead of shuffle\n    shuffle=False,\n    num_workers=2,\n    worker_init_fn=seed_worker,\n    generator=g,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=64,\n    shuffle=False,\n    num_workers=2,\n    worker_init_fn=seed_worker,\n    generator=g,\n    pin_memory=True\n)\n\n# =============================\n# 3) Model\n# =============================\nclass MFCC_CNN(nn.Module):\n    def __init__(self, n_classes=2):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 16, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout(0.25),\n\n            nn.Conv2d(16, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d((2,2)),\n            nn.Dropout(0.25),\n\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1,1)),\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.4),\n            nn.Linear(64, n_classes)\n        )\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # [B,1,40,320]\n        x = self.features(x)\n        return self.classifier(x)\n\nmodel = MFCC_CNN().to(device)\n\n# Loss: still keep class weights (fine), even though sampler already helps\ncw = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=train_labels)\ncw = torch.tensor(cw, dtype=torch.float32).to(device)\ncriterion = nn.CrossEntropyLoss(weight=cw)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# LR scheduler improves stability\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode=\"max\", factor=0.5, patience=2\n)\n\n\n# =============================\n# 4) Eval\n# =============================\ndef eval_macro_f1(model):\n    model.eval()\n    ys, ps = [], []\n    with torch.no_grad():\n        for x, y in val_loader:\n            x = x.to(device, non_blocking=True)\n            y = y.to(device, non_blocking=True)\n            logits = model(x)\n            pred = torch.argmax(logits, dim=1)\n            ys.extend(y.cpu().numpy().tolist())\n            ps.extend(pred.cpu().numpy().tolist())\n    return f1_score(ys, ps, average=\"macro\")\n\n# =============================\n# 5) Train with early stopping\n# =============================\nbest_f1 = -1.0\nbest_state = None\npatience = 6\nbad = 0\nEPOCHS = 30\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    total_loss = 0.0\n\n    for x, y in train_loader:\n        x = x.to(device, non_blocking=True)\n        y = y.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n        logits = model(x)\n        loss = criterion(logits, y)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    val_f1 = eval_macro_f1(model)\n    scheduler.step(val_f1)\n\n    print(f\"Epoch {epoch:02d} | train_loss={total_loss/len(train_loader):.4f} | val_macroF1={val_f1:.4f}\")\n\n    if val_f1 > best_f1 + 1e-4:\n        best_f1 = val_f1\n        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n        bad = 0\n    else:\n        bad += 1\n        if bad >= patience:\n            print(\"Early stopping.\")\n            break\n\n# Safety: best_state fallback\nif best_state is None:\n    print(\"‚ö†Ô∏è No improvement detected; saving last epoch weights.\")\nelse:\n    model.load_state_dict(best_state)\n\nprint(\"‚úÖ Best MFCC val macro-F1:\", best_f1)\n\nmfcc_path = os.path.join(SAVE_DIR, \"mfcc_cnn_tamil_16k_stratspk.pt\")\ntorch.save(model.state_dict(), mfcc_path)\nprint(\"‚úÖ Saved:\", mfcc_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:30:52.748120Z","iopub.execute_input":"2026-02-28T07:30:52.748864Z","iopub.status.idle":"2026-02-28T07:36:18.464371Z","shell.execute_reply.started":"2026-02-28T07:30:52.748833Z","shell.execute_reply":"2026-02-28T07:36:18.463602Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | train_loss=0.5904 | val_macroF1=0.1350\nEpoch 02 | train_loss=0.4274 | val_macroF1=0.7528\nEpoch 03 | train_loss=0.2113 | val_macroF1=0.7673\nEpoch 04 | train_loss=0.1635 | val_macroF1=0.8977\nEpoch 05 | train_loss=0.1255 | val_macroF1=0.8815\nEpoch 06 | train_loss=0.1163 | val_macroF1=0.8288\nEpoch 07 | train_loss=0.1271 | val_macroF1=0.9242\nEpoch 08 | train_loss=0.1024 | val_macroF1=0.8773\nEpoch 09 | train_loss=0.0830 | val_macroF1=0.8403\nEpoch 10 | train_loss=0.0921 | val_macroF1=0.8838\nEpoch 11 | train_loss=0.0740 | val_macroF1=0.9113\nEpoch 12 | train_loss=0.0671 | val_macroF1=0.8838\nEpoch 13 | train_loss=0.0915 | val_macroF1=0.9185\nEarly stopping.\n‚úÖ Best MFCC val macro-F1: 0.9241543443486403\n‚úÖ Saved: /kaggle/working/models_tamil/mfcc_cnn_tamil_16k_stratspk.pt\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"src = \"/kaggle/working/models_tamil/mfcc_cnn_tamil_16k_stratspk.pt\"\ndst = \"/kaggle/working/mfcc_cnn_tamil_16k_stratspk.pt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:37:20.555549Z","iopub.execute_input":"2026-02-28T07:37:20.556276Z","iopub.status.idle":"2026-02-28T07:37:20.560909Z","shell.execute_reply.started":"2026-02-28T07:37:20.556246Z","shell.execute_reply":"2026-02-28T07:37:20.560336Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Wev2Vec2","metadata":{}},{"cell_type":"code","source":"# ============================================\n# ‚úÖ FULL W2V2 TRAIN (KAGGLE): Tamil 16k + speaker-safe split\n# - Reads: /kaggle/working/Tamil_16k/tamil_trainval_16k_stratspk.csv\n# - Saves: /kaggle/working/DDDL_Tamil_Models/wav2vec2_tamil_16k_stratspk/{stage1,stage2,final}\n# ============================================\n\nimport os, random\nimport numpy as np\nimport pandas as pd\nimport torch, librosa\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom transformers import (\n    Wav2Vec2FeatureExtractor,\n    Wav2Vec2ForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n    EarlyStoppingCallback\n)\n\n# =============================\n# 0) Seeds / deterministic\n# =============================\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED)\ntorch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"‚úÖ device:\", device)\n\n# =============================\n# 1) Paths (Kaggle)\n# =============================\nCSV_PATH   = \"/kaggle/working/Tamil_16k/tamil_trainval_16k_stratspk.csv\"\nSAVE_ROOT  = \"/kaggle/working/DDDL_Tamil_Models\"\nW2V2_DIR   = os.path.join(SAVE_ROOT, \"wav2vec2_tamil_16k_stratspk\")\nos.makedirs(W2V2_DIR, exist_ok=True)\n\ndf = pd.read_csv(CSV_PATH)\nprint(\"‚úÖ CSV loaded:\", CSV_PATH)\nprint(df[\"split\"].value_counts())\nprint(df.groupby([\"split\",\"label\"]).size())\n\n# =============================\n# 2) Feature extractor\n# =============================\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\n    \"facebook/wav2vec2-xls-r-300m\",\n    sampling_rate=16000\n)\n\n# =============================\n# 3) Dataset + collate\n# =============================\nclass TamilW2V2Dataset(Dataset):\n    def __init__(self, df, split):\n        self.df = df[df[\"split\"] == split].reset_index(drop=True)\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        audio, _ = librosa.load(row[\"file_path\"], sr=16000, mono=True)\n        audio, _ = librosa.effects.trim(audio, top_db=30)\n        return {\"input_values\": audio, \"labels\": int(row[\"label\"])}\n\ntrain_ds = TamilW2V2Dataset(df, \"train\")\nval_ds   = TamilW2V2Dataset(df, \"val\")\n\ndef collate_fn(batch):\n    inputs = [b[\"input_values\"] for b in batch]\n    labels = torch.tensor([b[\"labels\"] for b in batch], dtype=torch.long)\n    feats = feature_extractor(inputs, sampling_rate=16000, padding=True, return_tensors=\"pt\")\n    feats[\"labels\"] = labels\n    return feats\n\n# =============================\n# 4) Class weights\n# =============================\ntrain_labels = df[df[\"split\"]==\"train\"][\"label\"].astype(int).values\ncw = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=train_labels)\ncw = torch.tensor(cw, dtype=torch.float32)  # keep CPU; move to device inside loss\nprint(\"‚úÖ class weights:\", cw.tolist())\n\n# =============================\n# 5) Weighted Trainer (version-proof)\n# =============================\nclass WeightedTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        w = cw.to(logits.device)\n        loss = torch.nn.functional.cross_entropy(logits, labels, weight=w)\n        return (loss, outputs) if return_outputs else loss\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    if isinstance(logits, (tuple, list)):\n        logits = logits[0]\n    preds = np.argmax(logits, axis=1)\n    return {\"f1\": f1_score(labels, preds, average=\"macro\")}\n\n# =============================\n# 6) Build model\n# =============================\nmodel = Wav2Vec2ForSequenceClassification.from_pretrained(\n    \"facebook/wav2vec2-xls-r-300m\",\n    num_labels=2,\n    problem_type=\"single_label_classification\"\n).to(device)\n\n# =============================\n# STAGE 1: Freeze encoder\n# =============================\nfor p in model.wav2vec2.parameters():\n    p.requires_grad = False\nfor p in model.classifier.parameters():\n    p.requires_grad = True\n\nargs_stage1 = TrainingArguments(\n    output_dir=os.path.join(W2V2_DIR, \"stage1\"),\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n\n    learning_rate=5e-5,\n    num_train_epochs=8,\n    warmup_steps=50,\n    weight_decay=0.01,\n\n    fp16=torch.cuda.is_available(),   # Kaggle GPU ‡¶π‡¶≤‡ßá True, ‡¶®‡¶æ ‡¶π‡¶≤‡ßá False\n    max_grad_norm=1.0,\n    logging_steps=50,\n    save_total_limit=2,\n    report_to=\"none\",\n    seed=SEED,\n    remove_unused_columns=False\n)\n\ntrainer1 = WeightedTrainer(\n    model=model,\n    args=args_stage1,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)\n\ntrainer1.train()\nprint(\"‚úÖ Stage1 best F1:\", trainer1.state.best_metric)\n\n# =============================\n# STAGE 2: Unfreeze last 2 layers (fp16 OFF for stability)\n# =============================\nfor p in model.wav2vec2.parameters():\n    p.requires_grad = False\n\nfor layer in model.wav2vec2.encoder.layers[-2:]:\n    for p in layer.parameters():\n        p.requires_grad = True\n\nfor p in model.classifier.parameters():\n    p.requires_grad = True\n\nargs_stage2 = TrainingArguments(\n    output_dir=os.path.join(W2V2_DIR, \"stage2\"),\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n\n    learning_rate=1e-5,\n    num_train_epochs=8,\n    warmup_steps=30,\n    weight_decay=0.01,\n\n    fp16=False,                 # ‚úÖ IMPORTANT\n    max_grad_norm=1.0,\n    logging_steps=50,\n    save_total_limit=2,\n    report_to=\"none\",\n    seed=SEED,\n    remove_unused_columns=False\n)\n\ntrainer2 = WeightedTrainer(\n    model=model,\n    args=args_stage2,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)\n\ntrainer2.train()\nprint(\"‚úÖ Stage2 best F1:\", trainer2.state.best_metric)\n\n# =============================\n# 7) Save FINAL (Kaggle)\n# =============================\nFINAL_DIR = os.path.join(W2V2_DIR, \"final\")\nos.makedirs(FINAL_DIR, exist_ok=True)\n\ntrainer2.model.save_pretrained(FINAL_DIR)\nfeature_extractor.save_pretrained(FINAL_DIR)\n\nprint(\"‚úÖ Saved FINAL W2V2:\", FINAL_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T07:37:26.404602Z","iopub.execute_input":"2026-02-28T07:37:26.405281Z","iopub.status.idle":"2026-02-28T07:55:30.067642Z","shell.execute_reply.started":"2026-02-28T07:37:26.405254Z","shell.execute_reply":"2026-02-28T07:55:30.066892Z"}},"outputs":[{"name":"stdout","text":"‚úÖ device: cuda\n‚úÖ CSV loaded: /kaggle/working/Tamil_16k/tamil_trainval_16k_stratspk.csv\nsplit\ntrain    1158\nval       216\nName: count, dtype: int64\nsplit  label\ntrain  0        736\n       1        422\nval    0        184\n       1         32\ndtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0738c5cc72a406ab800d7d406c8115b"}},"metadata":{}},{"name":"stdout","text":"‚úÖ class weights: [0.7866848111152649, 1.3720378875732422]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2768f6079b42fea852f3ea8d4a6e64"}},"metadata":{}},{"name":"stderr","text":"Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d205463061bb477399f2d7ec47615fbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d505da054ee4616b5399001a43fd710"}},"metadata":{}},{"name":"stderr","text":"\u001b[1mWav2Vec2ForSequenceClassification LOAD REPORT\u001b[0m from: facebook/wav2vec2-xls-r-300m\nKey                          | Status     | \n-----------------------------+------------+-\nproject_q.weight             | UNEXPECTED | \nquantizer.codevectors        | UNEXPECTED | \nquantizer.weight_proj.weight | UNEXPECTED | \nquantizer.weight_proj.bias   | UNEXPECTED | \nproject_hid.bias             | UNEXPECTED | \nproject_q.bias               | UNEXPECTED | \nproject_hid.weight           | UNEXPECTED | \nprojector.weight             | MISSING    | \nclassifier.weight            | MISSING    | \nclassifier.bias              | MISSING    | \nprojector.bias               | MISSING    | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92df022c466346c8b186b551e1124d14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='580' max='1160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 580/1160 09:58 < 10:00, 0.97 it/s, Epoch 4/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.338652</td>\n      <td>0.679687</td>\n      <td>0.459222</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.164657</td>\n      <td>0.625779</td>\n      <td>0.583333</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.994102</td>\n      <td>0.610906</td>\n      <td>0.572073</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.867909</td>\n      <td>0.632854</td>\n      <td>0.549652</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c28a25cbbf54cf9b2433159a98bc6a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0b28fba60e4575b99759b3aab59dc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67c0d8c60fa2414e9a91d1731b26d304"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0249e58805841f3b85150b692b9196e"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Stage1 best F1: 0.5833333333333333\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='435' max='1160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 435/1160 07:37 < 12:45, 0.95 it/s, Epoch 3/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.000148</td>\n      <td>0.619076</td>\n      <td>0.568329</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.849592</td>\n      <td>0.688829</td>\n      <td>0.443728</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.706982</td>\n      <td>0.863712</td>\n      <td>0.314580</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f76a5a82a6b1457fa6edf3ffb86ca7f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b8c747417074d7d994853698b62c5bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c81e6ef0aa54ef084189c5dc8e8eb4e"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Stage2 best F1: 0.5683288922725542\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a77a382b7d24907bb141d073afebe0c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Saved FINAL W2V2: /kaggle/working/DDDL_Tamil_Models/wav2vec2_tamil_16k_stratspk/final\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Ensemble Weight Tune","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# ‚úÖ Ensemble Tune (Kaggle) ‚Äî EXACT replica of your Colab code\n# (same logic, only paths changed to Kaggle)\n# ============================================================\n\nimport os, numpy as np, pandas as pd, torch, librosa\nfrom sklearn.metrics import f1_score\nfrom transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification\nimport torch.nn as nn\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nCSV_PATH = \"/kaggle/working/Tamil_16k/tamil_trainval_16k_stratspk.csv\"\ndf = pd.read_csv(CSV_PATH)\n\n# =============================\n# 1) MFCC model + extractor\n# =============================\ndef extract_mfcc(file_path, target_sr=16000, n_mfcc=40, max_len=320):\n    y, sr = librosa.load(file_path, sr=target_sr, mono=True)\n    y, _ = librosa.effects.trim(y, top_db=30)\n    mfcc = librosa.feature.mfcc(y=y, sr=target_sr, n_mfcc=n_mfcc)\n    mfcc = (mfcc - mfcc.mean()) / (mfcc.std() + 1e-6)\n    T = mfcc.shape[1]\n    if T < max_len:\n        mfcc = np.pad(mfcc, ((0,0),(0, max_len-T)), mode=\"constant\")\n    else:\n        mfcc = mfcc[:, :max_len]\n    return mfcc.astype(np.float32)\n\nclass MFCC_CNN(nn.Module):\n    def __init__(self, n_classes=2):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d((2,2)), nn.Dropout(0.25),\n            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n            nn.MaxPool2d((2,2)), nn.Dropout(0.25),\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1,1)),\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.4),\n            nn.Linear(64, n_classes)\n        )\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self.features(x)\n        return self.classifier(x)\n\nMFCC_PATH = \"/kaggle/working/models_tamil/mfcc_cnn_tamil_16k_stratspk.pt\"\nmfcc_model = MFCC_CNN().to(device)\nmfcc_model.load_state_dict(torch.load(MFCC_PATH, map_location=\"cpu\"))\nmfcc_model.eval()\n\n# =============================\n# 2) W2V2 model (load from FINAL, not checkpoint)\n# =============================\nW2V2_CKPT = \"/kaggle/working/DDDL_Tamil_Models/wav2vec2_tamil_16k_stratspk/final\"\n\n# Feature extractor from base model (same as your code)\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\n    \"facebook/wav2vec2-xls-r-300m\",\n    sampling_rate=16000\n)\n\nw2v2_model = Wav2Vec2ForSequenceClassification.from_pretrained(W2V2_CKPT).to(device)\nw2v2_model.eval()\n\nsoftmax = torch.nn.Softmax(dim=1)\n\n@torch.no_grad()\ndef mfcc_prob(file_path):\n    x = extract_mfcc(file_path)\n    x = torch.from_numpy(x).unsqueeze(0).to(device)\n    logits = mfcc_model(x)\n    return softmax(logits).squeeze(0).cpu().numpy()\n\n@torch.no_grad()\ndef w2v2_prob(file_path):\n    audio, _ = librosa.load(file_path, sr=16000, mono=True)\n    audio, _ = librosa.effects.trim(audio, top_db=30)\n    feats = feature_extractor([audio], sampling_rate=16000, padding=True, return_tensors=\"pt\")\n    feats = {k: v.to(device) for k, v in feats.items()}\n    logits = w2v2_model(**feats).logits\n    return softmax(logits).squeeze(0).cpu().numpy()\n\n# =============================\n# 3) Tune ensemble weight on VAL\n# =============================\nval_df = df[df[\"split\"]==\"val\"].reset_index(drop=True)\nval_labels = val_df[\"label\"].astype(int).values\n\nval_m = []\nval_w = []\nfor fp in val_df[\"file_path\"].tolist():\n    val_m.append(mfcc_prob(fp))\n    val_w.append(w2v2_prob(fp))\n\nval_m = np.stack(val_m)\nval_w = np.stack(val_w)\n\nbest_w = None\nbest_f1 = -1\n\nfor w in np.linspace(0, 1, 101):\n    p = w * val_m + (1 - w) * val_w\n    preds = np.argmax(p, axis=1)\n    f1 = f1_score(val_labels, preds, average=\"macro\")\n    if f1 > best_f1:\n        best_f1 = f1\n        best_w = float(w)\n\nprint(\"‚úÖ Best MFCC weight:\", best_w)\nprint(\"‚úÖ Best ensemble VAL macro-F1:\", best_f1)\n\n# Save weight to Kaggle working\nOUT_W = \"/kaggle/working/best_ensemble_weight_tamil.txt\"\nwith open(OUT_W, \"w\") as f:\n    f.write(str(best_w))\nprint(\"‚úÖ Saved best weight to:\", OUT_W)\n\n# Ready predictor\ndef ensemble_predict(file_path, w_mfcc=best_w):\n    p1 = mfcc_prob(file_path)\n    p2 = w2v2_prob(file_path)\n    p = w_mfcc * p1 + (1 - w_mfcc) * p2\n    return int(np.argmax(p)), p","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T08:52:43.779693Z","iopub.execute_input":"2026-02-28T08:52:43.780310Z","iopub.status.idle":"2026-02-28T08:52:55.394117Z","shell.execute_reply.started":"2026-02-28T08:52:43.780281Z","shell.execute_reply":"2026-02-28T08:52:55.393408Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/426 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bfe0ef2c16a4cb98060e70acc35d881"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Best MFCC weight: 0.64\n‚úÖ Best ensemble VAL macro-F1: 0.9333333333333333\n‚úÖ Saved best weight to: /kaggle/working/best_ensemble_weight_tamil.txt\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# ‚úÖ DD-DL FINAL PREDICTION (Tamil RUN2 - Ensemble, Kaggle)\n# - Reads wavs directly from Kaggle input folder (no zip)\n# - ensemble_predict() must be defined + models loaded before this cell\n# ============================================================\n\nimport os, glob\nimport pandas as pd\n\nTEAM_NAME = \"TriVector\"\nRUN = \"run2\"\n\nTEST_DIR = \"/kaggle/input/datasets/tahmimahoque/depression-det/Depression_det/Depression_det/Test-set-tamil/Test-set-tamil\"\nSAVE_DIR = \"/kaggle/working/submissions\"\nos.makedirs(SAVE_DIR, exist_ok=True)\n\n# 1) Collect wav files\nwavs = glob.glob(os.path.join(TEST_DIR, \"**\", \"*.wav\"), recursive=True) + \\\n       glob.glob(os.path.join(TEST_DIR, \"**\", \"*.WAV\"), recursive=True)\n\nassert len(wavs) > 0, f\"‚ùå No wav found in: {TEST_DIR}\"\nwavs = sorted(wavs)\nprint(\"‚úÖ Total test wavs:\", len(wavs))\n\n# 2) Predict (ensemble_predict MUST already be defined above)\ndef to_text_label(pred_int):\n    return \"Depressed\" if int(pred_int) == 1 else \"Non-depressed\"\n\nrows = []\nfor fp in wavs:\n    pred, _ = ensemble_predict(fp)   # ‚úÖ ensemble\n    file_id = os.path.splitext(os.path.basename(fp))[0]\n    rows.append({\"file_name\": file_id, \"labels\": to_text_label(pred)})\n\n# 3) Save CSV\ncsv_name = f\"{TEAM_NAME}_Tamil_{RUN}.csv\"\ncsv_path = os.path.join(SAVE_DIR, csv_name)\npd.DataFrame(rows).to_csv(csv_path, index=False)\n\nprint(\"‚úÖ Saved Tamil RUN2 CSV:\", csv_path)\nprint(pd.read_csv(csv_path).head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T08:53:00.562940Z","iopub.execute_input":"2026-02-28T08:53:00.563242Z","iopub.status.idle":"2026-02-28T08:53:11.763792Z","shell.execute_reply.started":"2026-02-28T08:53:00.563217Z","shell.execute_reply":"2026-02-28T08:53:11.763110Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Total test wavs: 160\n‚úÖ Saved Tamil RUN2 CSV: /kaggle/working/submissions/TriVector_Tamil_run2.csv\n  file_name         labels\n0        t1      Depressed\n1       t10  Non-depressed\n2      t100  Non-depressed\n3      t101  Non-depressed\n4      t102  Non-depressed\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nPRED_CSV = \"/kaggle/working/submissions/TriVector_Tamil_run2.csv\"\nGT_CSV   = \"/kaggle/input/datasets/tahmimahoque/depression-det/Tamil_GT.xlsx - tam.csv\"\n\npred = pd.read_csv(PRED_CSV)\ngt   = pd.read_csv(GT_CSV)\n\n# --- normalize ids (strip .wav) ---\ngt[\"id\"] = gt[\"filename\"].astype(str).str.replace(r\"\\.wav$\", \"\", regex=True).str.replace(r\"\\.WAV$\", \"\", regex=True)\npred[\"id\"] = pred[\"file_name\"].astype(str).str.replace(r\"\\.wav$\", \"\", regex=True).str.replace(r\"\\.WAV$\", \"\", regex=True)\n\n# map GT labels D/ND -> text\ngt[\"true\"] = gt[\"label\"].astype(str).str.strip().str.upper().map({\"D\":\"Depressed\", \"ND\":\"Non-depressed\"})\n\n# prediction label column\npred = pred.rename(columns={\"labels\":\"pred\"})\n\ndf = gt[[\"id\",\"true\"]].merge(pred[[\"id\",\"pred\"]], on=\"id\", how=\"inner\")\n\nprint(\"GT rows:\", len(gt), \"| Pred rows:\", len(pred), \"| Matched:\", len(df))\nprint(\"Sample GT ids:\", gt[\"id\"].head().tolist())\nprint(\"Sample Pred ids:\", pred[\"id\"].head().tolist())\n\n# if still 0, show unmatched examples\nif len(df) == 0:\n    gt_set = set(gt[\"id\"])\n    pr_set = set(pred[\"id\"])\n    print(\"Example in GT not in Pred:\", list(gt_set - pr_set)[:10])\n    print(\"Example in Pred not in GT:\", list(pr_set - gt_set)[:10])\n    raise SystemExit(\"‚ùå Still 0 match. Check file naming.\")\n\nlabels = [\"Non-depressed\", \"Depressed\"]\n\nprint(\"\\nüìä Classification Report:\\n\")\nprint(classification_report(df[\"true\"], df[\"pred\"], labels=labels, digits=4, zero_division=0))\n\ncm = confusion_matrix(df[\"true\"], df[\"pred\"], labels=labels)\n\nplt.figure(figsize=(6,5))\nplt.imshow(cm, cmap=\"Blues\", interpolation=\"nearest\")\nplt.title(\"Confusion Matrix (Tamil Ensemble)\", fontsize=14)\nplt.colorbar()\nplt.xticks(np.arange(len(labels)), labels)\nplt.yticks(np.arange(len(labels)), labels)\n\nthresh = cm.max()/2 if cm.max()>0 else 0\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        plt.text(j, i, str(cm[i,j]),\n                 ha=\"center\", va=\"center\",\n                 fontsize=12,\n                 color=\"white\" if cm[i,j] > thresh else \"black\")\n\nplt.ylabel(\"True label\")\nplt.xlabel(\"Predicted label\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T08:54:05.359312Z","iopub.execute_input":"2026-02-28T08:54:05.360060Z","iopub.status.idle":"2026-02-28T08:54:05.524407Z","shell.execute_reply.started":"2026-02-28T08:54:05.360033Z","shell.execute_reply":"2026-02-28T08:54:05.523771Z"}},"outputs":[{"name":"stdout","text":"GT rows: 160 | Pred rows: 160 | Matched: 160\nSample GT ids: ['t1', 't2', 't3', 't4', 't5']\nSample Pred ids: ['t1', 't10', 't100', 't101', 't102']\n\nüìä Classification Report:\n\n               precision    recall  f1-score   support\n\nNon-depressed     0.6723    1.0000    0.8040        80\n    Depressed     1.0000    0.5125    0.6777        80\n\n     accuracy                         0.7562       160\n    macro avg     0.8361    0.7562    0.7409       160\n weighted avg     0.8361    0.7562    0.7409       160\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}